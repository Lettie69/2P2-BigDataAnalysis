{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def connect_string(x, ms):\n",
    "    x = list(map(lambda i: sorted(i.split(ms)), x))\n",
    "    l = len(x[0])\n",
    "    r = []\n",
    "    for i in range(len(x)):\n",
    "        for j in range(i, len(x)):\n",
    "            if x[i][:l - 1] == x[j][:l - 1] and x[i][l - 1] != x[j][l - 1]:\n",
    "                r.append(x[i][:l - 1] + sorted([x[j][l - 1], x[i][l - 1]]))\n",
    "    return r\n",
    "\n",
    "\n",
    "def find_rule(d, support, confidence, ms=u'-'):\n",
    "    # 存储输出结果\n",
    "    result = pd.DataFrame(index=['support', 'confidence'])\n",
    "\n",
    "    # 1项集的支持度序列\n",
    "    support_series = 1.0 * d.sum(axis=0) / d.shape[0]\n",
    "    # 基于给定的最小支持度进行筛选,得到1项频繁集\n",
    "    column = list(support_series[support_series > support].index)\n",
    "\n",
    "    # 当1项频繁集个数大于1时\n",
    "    k = 0\n",
    "    while len(column) > 1:\n",
    "        k = k + 1\n",
    "        print(u'\\n正在进行第%s次搜索...' % k)\n",
    "        column = connect_string(column, ms)\n",
    "        print(u'数目：%s...' % len(column))\n",
    "        # 乘积为1表示两个项集同时发生，乘积为0表示不同发生\n",
    "        sf = lambda i: d[i].prod(axis=1, numeric_only=True)  # 新一批支持度的计算函数\n",
    "\n",
    "        # 创建连接数据，这一步耗时、耗内存最严重。当数据集较大时，可以考虑并行运算优化。\n",
    "        d_2 = pd.DataFrame(list(map(sf, column)), index=[ms.join(i) for i in column]).T\n",
    "\n",
    "        # 计算连接后的支持度\n",
    "        support_series_2 = 1.0 * d_2[[ms.join(i) for i in column]].sum() / len(d)\n",
    "        column = list(support_series_2[support_series_2 > support].index)  # 新一轮支持度筛选\n",
    "        support_series = support_series.append(support_series_2)\n",
    "\n",
    "        column2 = []\n",
    "        # 遍历可能的推理，如{A,B,C}究竟是A+B-->C还是B+C-->A还是C+A-->B？\n",
    "        for i in column:\n",
    "            i = i.split(ms)\n",
    "            for j in range(len(i)):\n",
    "                column2.append(i[:j] + i[j + 1:] + i[j:j + 1])\n",
    "\n",
    "        # 定义置信度序列\n",
    "        cofidence_series = pd.Series(index=[ms.join(i) for i in column2])\n",
    "        # 计算置信度序列\n",
    "        for i in column2:\n",
    "            cofidence_series[ms.join(i)] = support_series[ms.join(sorted(i))] / support_series[ms.join(i[:len(i) - 1])]\n",
    "\n",
    "        for i in cofidence_series[cofidence_series > confidence].index:  # 置信度筛选\n",
    "            result[i] = 0.0\n",
    "            result[i]['confidence'] = cofidence_series[i]\n",
    "            result[i]['support'] = support_series[ms.join(sorted(i.split(ms)))]\n",
    "\n",
    "    result = result.T.sort_values(['confidence', 'support'], ascending=False)  # 结果整理，输出\n",
    "    print(u'\\n结果为：')\n",
    "    print(result)\n",
    "    return result\n",
    "\n",
    "import chardet\n",
    "\n",
    "with open(r\"C:\\Users\\25809\\Downloads\\mobile_services.csv\", 'rb') as file:\n",
    "    rawdata = file.read(10000)\n",
    "    result = chardet.detect(rawdata)\n",
    "    encoding = result['encoding']\n",
    "    print(f\"Detected encoding: {encoding}\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # 加载数据\n",
    "    data = pd.read_csv(r'C:\\Users\\25809\\Downloads\\mobile_services.csv', encoding=encoding)\n",
    "    print('转换原数据到0-1矩阵')\n",
    "    ct = lambda x: pd.Series(1, index=x[pd.notnull(x)])\n",
    "    b = map(ct, data.values)\n",
    "    data = pd.DataFrame(list(b)).fillna(0)\n",
    "    # 删除中间变脸b\n",
    "    del b\n",
    "\n",
    "    support = 0.2  # 最小支持度\n",
    "    confidence = 0.5  # 最小置信度\n",
    "\n",
    "    find_rule(data, support, confidence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xlrd\n",
    "from mlxtend.frequent_patterns import apriori  # 生成频繁项集\n",
    "from mlxtend.frequent_patterns import association_rules  # 生成强关联规则\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")  # 用于排除警告\n",
    "\n",
    "import chardet\n",
    "\n",
    "# Read the first few bytes to detect encoding\n",
    "with open(r\"C:\\Users\\25809\\Downloads\\mobile_services.csv\", 'rb') as file:\n",
    "    rawdata = file.read(10000)\n",
    "    result = chardet.detect(rawdata)\n",
    "    encoding = result['encoding']\n",
    "    print(f\"Detected encoding: {encoding}\")\n",
    "\n",
    "def loaddata():\n",
    "    order_data = pd.read_csv(r\"C:\\Users\\25809\\Downloads\\mobile_services.csv\", header=0, encoding=encoding)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    dataSet = loaddata()\n",
    "    column_list = []\n",
    "    for var in dataSet:\n",
    "        column_list = set(column_list) | set(var)\n",
    "    print('转换原数据到0-1矩阵')\n",
    "    data = pd.DataFrame(np.zeros((len(dataSet), 169)), columns=column_list)\n",
    "    for i in range(len(dataSet)):\n",
    "        for j in dataSet[i]:\n",
    "            data.loc[i, j] += 1\n",
    "    # apriori算法\n",
    "    frequent_itemsets = apriori(data, min_support=0.02, use_colnames=True)\n",
    "    print(pd.DataFrame(frequent_itemsets))\n",
    "    pd.DataFrame(frequent_itemsets).to_csv('frequent_itemsets.csv')\n",
    "    # 生成关联准则\n",
    "    rules = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=0.35)\n",
    "    print(pd.DataFrame(rules))\n",
    "    pd.DataFrame(rules).to_csv('rules.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
